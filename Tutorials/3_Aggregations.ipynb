{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2020 Google Inc.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "<!--\n",
    "    Licensed to the Apache Software Foundation (ASF) under one\n",
    "    or more contributor license agreements.  See the NOTICE file\n",
    "    distributed with this work for additional information\n",
    "    regarding copyright ownership.  The ASF licenses this file\n",
    "    to you under the Apache License, Version 2.0 (the\n",
    "    \"License\"); you may not use this file except in compliance\n",
    "    with the License.  You may obtain a copy of the License at\n",
    "\n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "    Unless required by applicable law or agreed to in writing,\n",
    "    software distributed under the License is distributed on an\n",
    "    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "    KIND, either express or implied.  See the License for the\n",
    "    specific language governing permissions and limitations\n",
    "    under the License.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous notebooks covered element-wise operations, but, in order to aggregate data, we need operations that happen `PCollection`-wise.\n",
    "\n",
    "First, import the necessary resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam import Create, Map, ParDo, Flatten, Keys\n",
    "from apache_beam import Values, GroupByKey, CoGroupByKey, CombineGlobally, CombinePerKey\n",
    "from apache_beam import pvalue, window, WindowInto\n",
    "from apache_beam.transforms.util import WithKeys\n",
    "from apache_beam.transforms.combiners import Top, Mean, Count\n",
    "\n",
    "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
    "import apache_beam.runners.interactive.interactive_beam as ib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`GroupByKey`** takes a `PCollection` of key-value pairs and outputs each key with all values associated with that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "elements = [\n",
    "    {\"country\": \"China\", \"population\": 1389, \"continent\": \"Asia\"},\n",
    "    {\"country\": \"India\", \"population\": 1311, \"continent\": \"Asia\"},\n",
    "    {\"country\": \"USA\", \"population\": 331, \"continent\": \"America\"},\n",
    "    {\"country\": \"Australia\", \"population\": 25, \"continent\": \"Oceania\"},\n",
    "    {\"country\": \"Brazil\", \"population\": 212, \"continent\": \"America\"},\n",
    "]\n",
    "\n",
    "gbk = (p | \"Create\" >> Create(elements)\n",
    "         | \"Add Keys\" >> WithKeys(lambda x: x[\"continent\"])\n",
    "         | GroupByKey())\n",
    "\n",
    "ib.show(gbk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "Note that the output is the key and an iterable containing the values.\n",
    "\n",
    "Some of the basic combiner functions are already built-in:\n",
    "\n",
    "- **`Count`** takes a `PCollection` and outputs the amount of elements.  \n",
    "- **`Top`** outputs the *n* largest/smallest of a `PCollection` given a comparison.  \n",
    "- **`Mean`** outputs the arithmetic mean of a `PCollection`.\n",
    "\n",
    "Combiners can aggregate using the whole `PCollection` or by key using methods:\n",
    "\n",
    "- **`.Globally`** applies the combiner to the whole `PCollection`.\n",
    "- **`.PerKey`** applies the combiner for each key-value in the `Pcollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "def key_value_fn(element):\n",
    "    return (element['continent'], element['population'])\n",
    "\n",
    "elements = [\n",
    "    {\"country\": \"China\", \"population\": 1389, \"continent\": \"Asia\"},\n",
    "    {\"country\": \"India\", \"population\": 1311, \"continent\": \"Asia\"},\n",
    "    {\"country\": \"Japan\", \"population\": 126, \"continent\": \"Asia\"},        \n",
    "    {\"country\": \"USA\", \"population\": 331, \"continent\": \"America\"},\n",
    "    {\"country\": \"Ireland\", \"population\": 5, \"continent\": \"Europe\"},\n",
    "    {\"country\": \"Indonesia\", \"population\": 273, \"continent\": \"Asia\"},\n",
    "    {\"country\": \"Brazil\", \"population\": 212, \"continent\": \"America\"},\n",
    "    {\"country\": \"Egypt\", \"population\": 102, \"continent\": \"Africa\"},\n",
    "    {\"country\": \"Spain\", \"population\": 47, \"continent\": \"Europe\"},\n",
    "    {\"country\": \"Ghana\", \"population\": 31, \"continent\": \"Africa\"},\n",
    "    {\"country\": \"Australia\", \"population\": 25, \"continent\": \"Oceania\"},\n",
    "]\n",
    "\n",
    "create = (p | \"Create\" >> Create(elements)\n",
    "            | \"Map Keys\" >> Map(key_value_fn))\n",
    "\n",
    "element_count_total = create | \"Total Count\" >> Count.Globally()\n",
    "\n",
    "element_count_grouped = create | \"Count Per Key\" >> Count.PerKey()\n",
    "\n",
    "top_grouped = create | \"Top\" >> Top.PerKey(n=2) # We get the top 2\n",
    "\n",
    "mean_grouped = create | \"Mean\" >> Mean.PerKey()\n",
    "\n",
    "\n",
    "ib.show_graph(p)\n",
    "ib.show(element_count_total, element_count_grouped, top_grouped, mean_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "**`CoGroupByKey`** Aggregates all input elements by their key and allows downstream processing to consume all values associated with the key. While `GroupByKey` performs this operation over a single input collection and thus a single type of input values, `CoGroupByKey` operates over multiple input collections. As a result, the result for each key is a tuple of the values associated with that key in each input collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "jobs = [\n",
    "    (\"John\", \"Data Scientist\"),\n",
    "    (\"Rebecca\", \"Full Stack Engineer\"),\n",
    "    (\"John\", \"Data Engineer\"),\n",
    "    (\"Alice\", \"CEO\"),\n",
    "    (\"Charles\", \"Web Designer\"),\n",
    "]\n",
    "\n",
    "hobbies = [\n",
    "    (\"John\", \"Baseball\"),\n",
    "    (\"Rebecca\", \"Football\"),\n",
    "    (\"John\", \"Piano\"),\n",
    "    (\"Alice\", \"Photoshop\"),\n",
    "    (\"Charles\", \"Coding\"),\n",
    "    (\"Rebecca\", \"Acting\"),\n",
    "    (\"Rebecca\", \"Reading\")\n",
    "]\n",
    "\n",
    "jobs_create = p | \"Create Jobs\" >> Create(jobs)\n",
    "hobbies_create = p | \"Create Hobbies\" >> Create(hobbies)\n",
    "\n",
    "cogbk = (jobs_create, hobbies_create) | CoGroupByKey()\n",
    "\n",
    "ib.show_graph(p)\n",
    "ib.show(cogbk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br> \n",
    "\n",
    "This operation could be thought of as a `Flatten`+`GroupByKey`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you need to add your own logic to aggregate data, either in a global way or per key. For this, you can build your own combiners.  \n",
    "\n",
    "**`CombineGlobally`** takes a `PCollection` and outputs the aggregated value of the given function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "elements = [\"Lorem ipsum dolor sit amet. Consectetur adipiscing elit\",\n",
    "            \"Sed eu velit nec sem vulputate loborti\",\n",
    "            \"In lobortis augue vitae sagittis molestie. Mauris volutpat tortor non purus elementum\",\n",
    "            \"Ut blandit massa et risus sollicitudin auctor\"]\n",
    "\n",
    "combine = (p | \"Create\" >> Create(elements)\n",
    "             | \"Join\" >> CombineGlobally(lambda x: \". \".join(x)))\n",
    "\n",
    "ib.show(combine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br> \n",
    "\n",
    "Note that the order may change. Combiners are normally commutative (i.e., *a + b = b + a*) and associative (i.e., *a + (b + c)= (a + b) + c*) operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combiner can also be done per key:\n",
    "\n",
    "\n",
    "**`CombinePerKey`** takes a `PCollection` and outputs the aggregated value of the given function per key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "elements = [\n",
    "            (\"Latin\", \"Lorem ipsum dolor sit amet. Consectetur adipiscing elit. Sed eu velit nec sem vulputate loborti\"),\n",
    "            (\"Latin\", \"In lobortis augue vitae sagittis molestie. Mauris volutpat tortor non purus elementum\"),\n",
    "            (\"English\", \"From fairest creatures we desire increase\"),\n",
    "            (\"English\", \"That thereby beauty's rose might never die\"),\n",
    "            (\"English\", \"But as the riper should by time decease\"),\n",
    "            (\"Spanish\", \"En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\"),\n",
    "            (\"Spanish\", \"tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua\"),\n",
    "]\n",
    "\n",
    "combine_key = (p | \"Create\" >> Create(elements)\n",
    "                 | \"Join By Language\" >> CombinePerKey(lambda x: \". \".join(x)))\n",
    "\n",
    "ib.show_graph(p)\n",
    "ib.show(combine_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline creates key-value pairs of buyers and items. From these key-value pairs the pipeline extracts three things: the items each person bought, how many times each item was bought, and how many total items were bought.\n",
    "\n",
    "**Example**\n",
    "\n",
    "From values `(Bob, TV)`, `(Alice, TV)` and `(Bob, Speakers)` the output is that the TV was bought two times and the Speakers one time, there were a total of three items bought, and Bob bought a TV and a speaker and Alice just a TV.\n",
    "\n",
    "Since we are going to test if the pipeline is right, be sure to name the final pipelines `buyers`, `total_per_items` and `total_sum`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apache_beam.testing.util import assert_that\n",
    "from apache_beam.testing.util import matches_all, equal_to\n",
    "from utils.solutions import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "kvs = [(\"Bob\", \"TV\"),\n",
    "       (\"Alice\", \"TV\"),\n",
    "       (\"Pedro\", \"Speaker\"),\n",
    "       (\"Bob\", \"Speaker\"),\n",
    "       (\"Bob\", \"HDMI\"),\n",
    "       (\"Alice\", \"Controller\")]\n",
    "\n",
    "# TODO: Finish the pipeline \n",
    "create = p | \"Create\" >> Create(kvs)\n",
    "\n",
    "\n",
    "\n",
    "ib.show_graph(p)\n",
    "ib.show(buyers, total_per_items, total_sum)\n",
    "\n",
    "# For testing the solution - Don't modify\n",
    "assert_that(total_per_items, equal_to(solutions[3][\"total_per_items\"]), label=\"Total per item\")\n",
    "assert_that(total_sum, equal_to(solutions[3][\"total_sum\"]), label=\"Total sum\")\n",
    "assert_that(buyers | beam.MapTuple(lambda k, v: (k, sorted(v))), equal_to(solutions[3][\"buyers\"]), label=\"Buyers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get items per buyer**\n",
    "<details><summary>Hint</summary>\n",
    "<p>\n",
    "\n",
    "You need to take the `PCollection` and output the grouped values per key, this needs a `GroupByKey`.\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "<p>\n",
    "\n",
    "```\n",
    "buyers = create | \"GBK Buyer\" >> GroupByKey()\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count times each item was bought**\n",
    "<details><summary>Hint</summary>\n",
    "<p>\n",
    "\n",
    "Since the input is the same `create`, just branch it out. You need to aggregate the elements by key and, in this case, count them, hence you need `Count.PerKey`. But, since the input key is the buyer rather than the item, swap them before (there's a built-in operation but a `Map` suffices, also `MapTuple`).\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "total_per_items = (create | \"Invert keys\" >> Map(lambda x: (x[1], x[0]))\n",
    "                          | \"Count per key\" >> Count.PerKey())    \n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count total sells**\n",
    "<details><summary>Hint</summary>\n",
    "<p>\n",
    "\n",
    "There is more than one way to do this, you can take the input from `Create`, but that means each element is aggregated three times (`GroupByKey`, `Count.PerKey`, and this aggregation). A more efficient way is to sum the values that the `Count.PerKey` output (since it's already aggregated), but just with the values of the key-value pairs. Since there's no need to aggregate considering the key (there are no keys now), you can use `Combine.Globally`. \n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "<p>\n",
    "\n",
    "```\n",
    "total_sum = (total_per_items | Values()\n",
    "                             | CombineGlobally(sum))    \n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full code**\n",
    "<details><summary>Code</summary>\n",
    "<p>\n",
    "\n",
    "```\n",
    "p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "kvs = [(\"Bob\", \"TV\"),\n",
    "       (\"Alice\", \"TV\"),\n",
    "       (\"Pedro\", \"Speaker\"),\n",
    "       (\"Bob\", \"Speaker\"),\n",
    "       (\"Bob\", \"HDMI\"),\n",
    "       (\"Alice\", \"Controller\")]\n",
    "\n",
    "\n",
    "# TODO: Finish the pipeline \n",
    "create = p | \"Create\" >> Create(kvs)\n",
    "\n",
    "buyers = create | \"GBK Buyer\" >> GroupByKey()\n",
    "\n",
    "total_per_items = (create | \"Invert keys\" >> Map(lambda x: (x[1], x[0]))\n",
    "                          | \"Count per key\" >> Count.PerKey())\n",
    "\n",
    "total_sum = (total_per_items | Values()\n",
    "                             | CombineGlobally(sum))\n",
    "\n",
    "ib.show_graph(p)\n",
    "ib.show(buyers, total_per_items, total_sum)\n",
    "\n",
    "# For testing the solution - Don't modify\n",
    "assert_that(total_per_items, equal_to(solutions[3][\"total_per_items\"]), label=\"Total per item\")\n",
    "assert_that(total_sum, equal_to(solutions[3][\"total_sum\"]), label=\"Total sum\")\n",
    "assert_that(buyers | beam.MapTuple(lambda k, v: (k, sorted(v))), equal_to(solutions[3][\"buyers\"]), label=\"Buyers\")\n",
    "```\n",
    "</p>\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

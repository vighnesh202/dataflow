{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb95919-7460-467f-b701-dff639a650d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (4.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1489614a-847f-43af-90f7-d1bc05580344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File node    proc > summary\n",
      "File tag       ::title:text\n",
      "parent              ::title\n",
      "Name: 1, dtype: object\n",
      "File node           proc > summary\n",
      "File tag     ::title:append to log\n",
      "parent                     ::title\n",
      "Name: 2, dtype: object\n",
      "{'text': [None, None], 'append_to_log': ['\"true val\"', '\"value2\"']}\n",
      "File node                   proc > summary\n",
      "File tag     ::auxiliary headers text file\n",
      "parent                                None\n",
      "Name: 0, dtype: object\n",
      "File node            proc > summary\n",
      "File tag     ::check for amplitudes\n",
      "parent                         None\n",
      "Name: 3, dtype: object\n",
      "{'auxiliary_headers_text_file': [None, '\"value2 auxillary\"'], 'check_for_amplitudes': ['\"true\"', '\"true\"']}\n"
     ]
    }
   ],
   "source": [
    "# code2 \n",
    "# {\"proc\":{\"summary\":{\"title\":[{\"text\":\"None\",\"append_to_tag\":\"false\"},{\"text\":\"None\",\"append_to_tag\":\"true\"}]}}}\n",
    "import re\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "parser = etree.XMLParser(encoding='utf-8')\n",
    "# Reading the XML file\n",
    "docTree = etree.parse(\"pgs.jobxml\", parser)\n",
    "\n",
    "def flatten(a):\n",
    "    first_value_len = len(list(a.values())[0])\n",
    "    v=[]\n",
    "    for i in range(first_value_len):\n",
    "        l={}\n",
    "        #print(i)\n",
    "        for qk, qv in a.items():\n",
    "            #print(qk)\n",
    "            l[qk] = qv[i]\n",
    "        if not all(value == None for value in l.values()):\n",
    "            v.append(l)\n",
    "    return v\n",
    "\n",
    "resultant_json = {\"proc\": {\"summary\": {\"title\": [{\"append_to_tag\": \"\", \"text\": \"\"}],\n",
    "                                       \"auxiliary_headers_text_file\": []}}}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "for i, j in df.groupby(\"parent\"):\n",
    "    #print(i)\n",
    "    #print(j)\n",
    "    #print(\"#\")\n",
    "    values={}\n",
    "    \n",
    "    for k, l in j.iterrows():\n",
    "        \n",
    "        # find how many summary elements are present\n",
    "        path_prefix = l['File node']\n",
    "        #xpath=\"/Parser/job/proc/summary\"\n",
    "        docTree.xpath(xpath)\n",
    "        xpath = \"//\" + \"/\".join(path_prefix.split(\">\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        tag = str(l[\"File tag\"])\n",
    "        #print(tag)\n",
    "        xpath_constructor = ''\n",
    "        xpath_constructor = \"//\" + \"/\".join(path_prefix.split(\">\")) + \"/Param/Path[text()='{}']/..\".format(tag)\n",
    "        #print(tag)\n",
    "        tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)][-1]\n",
    "        #print(tag_value)\n",
    "        whole_tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)]\n",
    "        #print(path_prefix.split(\">\"))\n",
    "        #print(whole_tag_value)\n",
    "        \n",
    "        values[tag_value]=[]\n",
    "        for path in docTree.xpath(xpath_constructor):\n",
    "            if path.xpath(\"./Content\"):\n",
    "                values[tag_value].append((path.xpath(\"./Content\")[0].text))\n",
    "            else:\n",
    "                values[tag_value].append(None)\n",
    "        #print(i)\n",
    "        #if i == \"None\":\n",
    "        #   print(values)\n",
    "        #print(values)\n",
    "        #print(\"#\")\n",
    "    #print(values)\n",
    "    #path_prefix = l['File node'].split(\">\")\n",
    "    #parent = l['parent']\n",
    "    #print(path_prefix)\n",
    "    #print(parent)\n",
    "    combined={}\n",
    "    print(values)\n",
    "    #for q in combined:\n",
    "    #print(values)\n",
    "    #print(\"###\")\n",
    "    #print(flatten(values))\n",
    "    #print(\"%%%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b6dbf3b-f0eb-4bc5-9391-4e8b9f38e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent: ::title\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"true val\"\n",
      "###\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"value2\"\n",
      "###\n",
      "parent: None\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "None\n",
      "###\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "value: \"value2 auxillary\"\n",
      "###\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# code 3\n",
    "import re\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "parser = etree.XMLParser(encoding='utf-8')\n",
    "# Reading the XML file\n",
    "docTree = etree.parse(\"pgs.jobxml\", parser)\n",
    "\n",
    "def flatten(a):\n",
    "    first_value_len = len(list(a.values())[0])\n",
    "    v=[]\n",
    "    for i in range(first_value_len):\n",
    "        l={}\n",
    "        #print(i)\n",
    "        for qk, qv in a.items():\n",
    "            #print(qk)\n",
    "            l[qk] = qv[i]\n",
    "        if not all(value == None for value in l.values()):\n",
    "            v.append(l)\n",
    "    return v\n",
    "\n",
    "#resultant_json = {\"proc\": {\"summary\": {\"title\": [{\"append_to_tag\": \"\", \"text\": \"\"}],\n",
    "#                                       \"auxiliary_headers_text_file\": []}}}\n",
    "\n",
    "resultant_json = {\"proc\":{\"summary\":[\n",
    "    {\"title\":{\"append_to_tag\":\"\",\"text\":\"\"},\n",
    "     \"auxiliary_headers_text_file\":\"\",\n",
    "     \"check_for_amplitudes\":\"\"}]}}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "for i, j in df.groupby(\"parent\"):\n",
    "    print(\"parent: {}\".format(i))\n",
    "    values={}\n",
    "    parent = i\n",
    "    # find how many summary elements are present\n",
    "    path_prefix = j['File node'].iloc[0]\n",
    "    xpath = \"//\" + \"/\".join(path_prefix.split(\">\"))\n",
    "    number_of_elements = len(docTree.xpath(xpath))\n",
    "    #print(number_of_elements)\n",
    "    v = []\n",
    "    for element_number in range(number_of_elements):\n",
    "        for k, l in j.iterrows():\n",
    "            tag = str(l[\"File tag\"])\n",
    "            xpath_constructor = ''\n",
    "            xpath_constructor = \"//\" + \"/\".join(path_prefix.split(\">\")) + \"/Param/Path[text()='{}']/..\".format(tag)\n",
    "            whole_tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)]\n",
    "            print(\"tag: {}\".format(whole_tag_value))\n",
    "            print(xpath_constructor)\n",
    "            current_path = docTree.xpath(xpath_constructor)[element_number]\n",
    "            if current_path.xpath(\"./Content\"):\n",
    "                print(\"value: {}\".format(current_path.xpath(\"./Content\")[0].text))\n",
    "                #values[tag_value].append((path.xpath(\"./Content\")[0].text))\n",
    "            else:\n",
    "                print(None)\n",
    "                #values[tag_value].append(None)\n",
    "            print(\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2ca6d52-b557-4c5f-abfa-017f2abebc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docTree.xpath(\"//proc/summary/Param/Path[text()='::title:text']/../Content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "350a2130-a7e9-461c-8665-7cd9fa3a0697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***file type***\n",
      "proc > summary\n",
      "***group: ::title***\n",
      "***group: None***\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "for i, j in df.groupby(\"File node\"):\n",
    "    print(\"***file type***\")\n",
    "    print(i)\n",
    "    for i1, j1 in j.groupby(\"parent\"):\n",
    "        print(\"***group: {}***\".format(i1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "23575ceb-2096-4fc7-b712-a84f8f1ee559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent: proc > dataread\n",
      "tag: ['input', 'project_name']\n",
      "//proc / dataread/Param/Path[text()='::input:project name']/..\n",
      "None\n",
      "###\n",
      "::input:project name\n",
      "20\n",
      "bvc\n",
      "::input:project name\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "tag: ['input', 'folder', 'folder_name']\n",
      "//proc / dataread/Param/Path[text()='::input:folder:folder name']/..\n",
      "None\n",
      "###\n",
      "::input:folder:folder name\n",
      "26\n",
      "bvc\n",
      "::input:folder:folder name\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "tag: ['input', 'folder', 'dataset_name']\n",
      "//proc / dataread/Param/Path[text()='::input:folder:dataset name']/..\n",
      "value: \"h001j01_modelR999_vol_Leste_Epsilon_125x125x5_mrg_contour\"\n",
      "###\n",
      "::input:folder:dataset name\n",
      "27\n",
      "bvc\n",
      "::input:folder:dataset name\n",
      "****string*****\n",
      "\"h001j01_modelR999_vol_Leste_Epsilon_125x125x5_mrg_contour\"\n",
      "\"h001j01_modelR999_vol_Leste_Epsilon_125x125x5_mrg_contour\"\n",
      "tag: ['file_key']\n",
      "//proc / dataread/Param/Path[text()='::file key']/..\n",
      "None\n",
      "###\n",
      "::file key\n",
      "10\n",
      "::file key\n",
      "{'input': {'project_name': 'None', 'folder': {'folder_name': 'None', 'dataset_name': '\"h001j01_modelR999_vol_Leste_Epsilon_125x125x5_mrg_contour\"'}}, 'file_key': 'None'}\n",
      "parent: proc > summary\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "None\n",
      "###\n",
      "::auxiliary headers text file\n",
      "29\n",
      "::auxiliary headers text file\n",
      "{'auxiliary_headers_text_file': 'None'}\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "::title:text\n",
      "12\n",
      "bvc\n",
      "::title:text\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"true val\"\n",
      "###\n",
      "::title:append to log\n",
      "21\n",
      "bvc\n",
      "::title:append to log\n",
      "****string*****\n",
      "\"true val\"\n",
      "\"true val\"\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::check for amplitudes\n",
      "22\n",
      "::check for amplitudes\n",
      "{'auxiliary_headers_text_file': 'None', 'title': {'text': 'None', 'append_to_log': '\"true val\"'}, 'check_for_amplitudes': '\"true\"'}\n",
      "tag: ['parameters_database', 'overwrite']\n",
      "//proc / summary/Param/Path[text()='::parameters database:overwrite']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::parameters database:overwrite\n",
      "31\n",
      "bvc\n",
      "::parameters database:overwrite\n",
      "****string*****\n",
      "\"true\"\n",
      "\"true\"\n",
      "tag: ['parameters_database', 'pdb_prefix']\n",
      "//proc / summary/Param/Path[text()='::parameters database:pdb prefix']/..\n",
      "value: \"RF_\"\n",
      "###\n",
      "::parameters database:pdb prefix\n",
      "32\n",
      "bvc\n",
      "::parameters database:pdb prefix\n",
      "****string*****\n",
      "\"RF_\"\n",
      "\"RF_\"\n",
      "tag: ['parameters_database', 'project_name']\n",
      "//proc / summary/Param/Path[text()='::parameters database:project name']/..\n",
      "None\n",
      "###\n",
      "::parameters database:project name\n",
      "34\n",
      "bvc\n",
      "::parameters database:project name\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "tag: ['parameters_database', 'line_name', 'extract_from_job']\n",
      "//proc / summary/Param/Path[text()='::parameters database:line name:extract from job']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::parameters database:line name:extract from job\n",
      "48\n",
      "bvc\n",
      "::parameters database:line name:extract from job\n",
      "****string*****\n",
      "\"true\"\n",
      "\"true\"\n",
      "tag: ['parameters_database', 'line_name', 'pdb_name']\n",
      "//proc / summary/Param/Path[text()='::parameters database:line name:pdb name']/..\n",
      "None\n",
      "###\n",
      "::parameters database:line name:pdb name\n",
      "40\n",
      "bvc\n",
      "::parameters database:line name:pdb name\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "value: \"value2 auxillary\"\n",
      "###\n",
      "::auxiliary headers text file\n",
      "29\n",
      "::auxiliary headers text file\n",
      "{'auxiliary_headers_text_file': '\"value2 auxillary\"'}\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "::title:text\n",
      "12\n",
      "bvc\n",
      "::title:text\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"value2\"\n",
      "###\n",
      "::title:append to log\n",
      "21\n",
      "bvc\n",
      "::title:append to log\n",
      "****string*****\n",
      "\"value2\"\n",
      "\"value2\"\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::check for amplitudes\n",
      "22\n",
      "::check for amplitudes\n",
      "{'auxiliary_headers_text_file': '\"value2 auxillary\"', 'title': {'text': 'None', 'append_to_log': '\"value2\"'}, 'check_for_amplitudes': '\"true\"'}\n",
      "tag: ['parameters_database', 'overwrite']\n",
      "//proc / summary/Param/Path[text()='::parameters database:overwrite']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::parameters database:overwrite\n",
      "31\n",
      "bvc\n",
      "::parameters database:overwrite\n",
      "****string*****\n",
      "\"true\"\n",
      "\"true\"\n",
      "tag: ['parameters_database', 'pdb_prefix']\n",
      "//proc / summary/Param/Path[text()='::parameters database:pdb prefix']/..\n",
      "value: \"RF_\"\n",
      "###\n",
      "::parameters database:pdb prefix\n",
      "32\n",
      "bvc\n",
      "::parameters database:pdb prefix\n",
      "****string*****\n",
      "\"RF_\"\n",
      "\"RF_\"\n",
      "tag: ['parameters_database', 'project_name']\n",
      "//proc / summary/Param/Path[text()='::parameters database:project name']/..\n",
      "None\n",
      "###\n",
      "::parameters database:project name\n",
      "34\n",
      "bvc\n",
      "::parameters database:project name\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "tag: ['parameters_database', 'line_name', 'extract_from_job']\n",
      "//proc / summary/Param/Path[text()='::parameters database:line name:extract from job']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::parameters database:line name:extract from job\n",
      "48\n",
      "bvc\n",
      "::parameters database:line name:extract from job\n",
      "****string*****\n",
      "\"true\"\n",
      "\"true\"\n",
      "tag: ['parameters_database', 'line_name', 'pdb_name']\n",
      "//proc / summary/Param/Path[text()='::parameters database:line name:pdb name']/..\n",
      "None\n",
      "###\n",
      "::parameters database:line name:pdb name\n",
      "40\n",
      "bvc\n",
      "::parameters database:line name:pdb name\n",
      "****string*****\n",
      "None\n",
      "None\n",
      "########\n",
      "{\"proc\": {\"dataread\": [{\"input\": {\"project_name\": \"None\", \"folder\": {\"folder_name\": \"None\", \"dataset_name\": \"\\\"h001j01_modelR999_vol_Leste_Epsilon_125x125x5_mrg_contour\\\"\"}}, \"file_key\": \"None\"}], \"summary\": [{\"auxiliary_headers_text_file\": \"None\", \"title\": {\"text\": \"None\", \"append_to_log\": \"\\\"true val\\\"\"}, \"check_for_amplitudes\": \"\\\"true\\\"\", \"parameters_database\": {\"overwrite\": \"\\\"true\\\"\", \"pdb_prefix\": \"\\\"RF_\\\"\", \"project_name\": \"None\", \"line_name\": {\"extract_from_job\": \"\\\"true\\\"\", \"pdb_name\": \"None\"}}}, {\"auxiliary_headers_text_file\": \"\\\"value2 auxillary\\\"\", \"title\": {\"text\": \"None\", \"append_to_log\": \"\\\"value2\\\"\"}, \"check_for_amplitudes\": \"\\\"true\\\"\", \"parameters_database\": {\"overwrite\": \"\\\"true\\\"\", \"pdb_prefix\": \"\\\"RF_\\\"\", \"project_name\": \"None\", \"line_name\": {\"extract_from_job\": \"\\\"true\\\"\", \"pdb_name\": \"None\"}}}]}}\n"
     ]
    }
   ],
   "source": [
    "# code 4\n",
    "import re\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "parser = etree.XMLParser(encoding='utf-8')\n",
    "# Reading the XML file\n",
    "docTree = etree.parse(\"pgs.jobxml\", parser)\n",
    "\n",
    "def flatten(a):\n",
    "    first_value_len = len(list(a.values())[0])\n",
    "    v=[]\n",
    "    for i in range(first_value_len):\n",
    "        l={}\n",
    "        #print(i)\n",
    "        for qk, qv in a.items():\n",
    "            #print(qk)\n",
    "            l[qk] = qv[i]\n",
    "        if not all(value == None for value in l.values()):\n",
    "            v.append(l)\n",
    "    return v\n",
    "\n",
    "#resultant_json = {\"proc\": {\"summary\": {\"title\": [{\"append_to_tag\": \"\", \"text\": \"\"}],\n",
    "#                                       \"auxiliary_headers_text_file\": []}}}\n",
    "\n",
    "resultant_json = {\"proc\":{\"summary\":[\n",
    "    {\"title\":{\"append_to_tag\":\"\",\"text\":\"\"},\n",
    "     \"auxiliary_headers_text_file\":\"\",\n",
    "     \"check_for_amplitudes\":\"\"}]}}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata_3.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "\n",
    "values={}\n",
    "for i, j in df.groupby(\"File node\"):\n",
    "    print(\"parent: {}\".format(i))\n",
    "    \n",
    "    parent = i\n",
    "    # find how many summary elements are present\n",
    "    path_prefix = j['File node'].iloc[0]\n",
    "    xpath = \"//\" + \"/\".join(path_prefix.split(\">\"))\n",
    "    number_of_elements = len(docTree.xpath(xpath))\n",
    "    #print(number_of_elements)\n",
    "    \n",
    "    json_prefix = [p1.strip() for p1 in path_prefix.split(\">\")]\n",
    "    v = []\n",
    "    for element_number in range(number_of_elements):\n",
    "        v1 = {}\n",
    "        for k, l in j.iterrows():\n",
    "            tag = str(l[\"File tag\"])\n",
    "            xpath_constructor = ''\n",
    "            xpath_constructor = \"//\" + \"/\".join(path_prefix.split(\">\")) + \"/Param/Path[text()='{}']/..\".format(tag)\n",
    "            whole_tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)]\n",
    "            print(\"tag: {}\".format(whole_tag_value))\n",
    "            print(xpath_constructor)\n",
    "            current_path = docTree.xpath(xpath_constructor)[element_number]\n",
    "            current_value=''\n",
    "            if current_path.xpath(\"./Content\"):\n",
    "                current_value = current_path.xpath(\"./Content\")[0].text\n",
    "                print(\"value: {}\".format(current_path.xpath(\"./Content\")[0].text))\n",
    "                #values[tag_value].append((path.xpath(\"./Content\")[0].text))\n",
    "            else:\n",
    "                current_value = None\n",
    "                print(None)\n",
    "                #values[tag_value].append(None)\n",
    "            print(\"###\")\n",
    "            print(tag)\n",
    "            print(len(tag))\n",
    "            if len(whole_tag_value) > 1:\n",
    "                print(\"bvc\")\n",
    "                print(tag)\n",
    "                #for i1 in tag[:-1]:\n",
    "                    #if i1 in v1:\n",
    "                #v1.setdefault(whole_tag_value[0],{}).update({whole_tag_value[-1]: current_value})\n",
    "                #d = {}\n",
    "                d2 = v1\n",
    "                key_lst = whole_tag_value\n",
    "                #value = '1'\n",
    "                for k in key_lst[:-1]:\n",
    "                    d2 = d2.setdefault(k, {})\n",
    "                print(\"****string*****\")\n",
    "                print(current_value)\n",
    "                print(str(current_value))\n",
    "                d2[key_lst[-1]] = str(current_value)\n",
    "                \n",
    "            else:\n",
    "                print(tag)\n",
    "                v1[whole_tag_value[-1]] = str(current_value)\n",
    "                print(v1)\n",
    "        v.append(v1)\n",
    "    \n",
    "    d2 = values\n",
    "    key_lst = json_prefix\n",
    "    for k in key_lst[:-1]:\n",
    "        d2 = d2.setdefault(k, {})\n",
    "    d2[key_lst[-1]] = v\n",
    "      \n",
    "import json\n",
    "print(\"########\")\n",
    "print(json.dumps(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a86a7243-ab8f-40f5-aab2-01cd75791ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': {}}\n",
      "{}\n",
      "{'text': '2'}\n"
     ]
    }
   ],
   "source": [
    "c={}\n",
    "q=['title', 'text']\n",
    "for i in q[:-1]:\n",
    "    if not i in c:\n",
    "        c[i] = {}\n",
    "    print(c)\n",
    "    c = c[i]\n",
    "    print(c)\n",
    "#print(c)\n",
    "c[q[-1]] = '2'\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbea9765-d783-4cf4-9ba4-7323aa887258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{'w': 'v'}\n"
     ]
    }
   ],
   "source": [
    "k=['title', 'm1', 'text']\n",
    "\n",
    "c={}\n",
    "\n",
    "for i in k:\n",
    "    c.setdefault(i,{})\n",
    "    c=c[i]\n",
    "    print(c)\n",
    "c['w']='v'\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87ef5394-7960-4fd2-9a9f-a4ade2985a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k1': {'k2': {}}}\n",
      "{'b': 'q'}\n"
     ]
    }
   ],
   "source": [
    "tree = {}\n",
    "\n",
    "def add_to_tree(root, value_string):\n",
    "    \"\"\"Given a string of characters `value_string`, create or update a\n",
    "    series of dictionaries where the value at each level is a dictionary of\n",
    "    the characters that have been seen following the current character.\n",
    "    \"\"\"\n",
    "    for character in value_string:\n",
    "        root = root.setdefault(character, {})\n",
    "        \n",
    "add_to_tree(tree, ['title', 'text'])\n",
    "print(tree)\n",
    "\n",
    "for i in ['k1', 'k2']:\n",
    "    tree = tree[i]\n",
    "\n",
    "tree['b']='q'\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "514a8288-ff51-438b-96fa-aa3bb6251a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': {'text': {'m1': '1'}}}\n"
     ]
    }
   ],
   "source": [
    "# dictionary formation\n",
    "d = {}\n",
    "d2 = d\n",
    "key_lst = ['title', 'text', 'm1']\n",
    "value = '1'\n",
    "for k in key_lst[:-1]:\n",
    "    d2 = d2.setdefault(k, {})\n",
    "d2[key_lst[-1]] = value\n",
    "print(d)\n",
    "# {'key1': {'key2': {'key3': 'my_value'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b848a-415b-4b89-b72b-d499070486d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb95919-7460-467f-b701-dff639a650d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (4.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1489614a-847f-43af-90f7-d1bc05580344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File node    proc > summary\n",
      "File tag       ::title:text\n",
      "parent              ::title\n",
      "Name: 1, dtype: object\n",
      "File node           proc > summary\n",
      "File tag     ::title:append to log\n",
      "parent                     ::title\n",
      "Name: 2, dtype: object\n",
      "{'text': [None, None], 'append_to_log': ['\"true val\"', '\"value2\"']}\n",
      "File node                   proc > summary\n",
      "File tag     ::auxiliary headers text file\n",
      "parent                                None\n",
      "Name: 0, dtype: object\n",
      "File node            proc > summary\n",
      "File tag     ::check for amplitudes\n",
      "parent                         None\n",
      "Name: 3, dtype: object\n",
      "{'auxiliary_headers_text_file': [None, '\"value2 auxillary\"'], 'check_for_amplitudes': ['\"true\"', '\"true\"']}\n"
     ]
    }
   ],
   "source": [
    "# code2 \n",
    "# {\"proc\":{\"summary\":{\"title\":[{\"text\":\"None\",\"append_to_tag\":\"false\"},{\"text\":\"None\",\"append_to_tag\":\"true\"}]}}}\n",
    "import re\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "parser = etree.XMLParser(encoding='utf-8')\n",
    "# Reading the XML file\n",
    "docTree = etree.parse(\"pgs.jobxml\", parser)\n",
    "\n",
    "def flatten(a):\n",
    "    first_value_len = len(list(a.values())[0])\n",
    "    v=[]\n",
    "    for i in range(first_value_len):\n",
    "        l={}\n",
    "        #print(i)\n",
    "        for qk, qv in a.items():\n",
    "            #print(qk)\n",
    "            l[qk] = qv[i]\n",
    "        if not all(value == None for value in l.values()):\n",
    "            v.append(l)\n",
    "    return v\n",
    "\n",
    "resultant_json = {\"proc\": {\"summary\": {\"title\": [{\"append_to_tag\": \"\", \"text\": \"\"}],\n",
    "                                       \"auxiliary_headers_text_file\": []}}}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "for i, j in df.groupby(\"parent\"):\n",
    "    #print(i)\n",
    "    #print(j)\n",
    "    #print(\"#\")\n",
    "    values={}\n",
    "    \n",
    "    for k, l in j.iterrows():\n",
    "        \n",
    "        # find how many summary elements are present\n",
    "        path_prefix = l['File node']\n",
    "        #xpath=\"/Parser/job/proc/summary\"\n",
    "        docTree.xpath(xpath)\n",
    "        xpath = \"//\" + \"/\".join(path_prefix.split(\">\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        tag = str(l[\"File tag\"])\n",
    "        #print(tag)\n",
    "        xpath_constructor = ''\n",
    "        xpath_constructor = \"//\" + \"/\".join(path_prefix.split(\">\")) + \"/Param/Path[text()='{}']/..\".format(tag)\n",
    "        #print(tag)\n",
    "        tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)][-1]\n",
    "        #print(tag_value)\n",
    "        whole_tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)]\n",
    "        #print(path_prefix.split(\">\"))\n",
    "        #print(whole_tag_value)\n",
    "        \n",
    "        values[tag_value]=[]\n",
    "        for path in docTree.xpath(xpath_constructor):\n",
    "            if path.xpath(\"./Content\"):\n",
    "                values[tag_value].append((path.xpath(\"./Content\")[0].text))\n",
    "            else:\n",
    "                values[tag_value].append(None)\n",
    "        #print(i)\n",
    "        #if i == \"None\":\n",
    "        #   print(values)\n",
    "        #print(values)\n",
    "        #print(\"#\")\n",
    "    #print(values)\n",
    "    #path_prefix = l['File node'].split(\">\")\n",
    "    #parent = l['parent']\n",
    "    #print(path_prefix)\n",
    "    #print(parent)\n",
    "    combined={}\n",
    "    print(values)\n",
    "    #for q in combined:\n",
    "    #print(values)\n",
    "    #print(\"###\")\n",
    "    #print(flatten(values))\n",
    "    #print(\"%%%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b6dbf3b-f0eb-4bc5-9391-4e8b9f38e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent: ::title\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"true val\"\n",
      "###\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"value2\"\n",
      "###\n",
      "parent: None\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "None\n",
      "###\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "value: \"value2 auxillary\"\n",
      "###\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# code 3\n",
    "import re\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "parser = etree.XMLParser(encoding='utf-8')\n",
    "# Reading the XML file\n",
    "docTree = etree.parse(\"pgs.jobxml\", parser)\n",
    "\n",
    "def flatten(a):\n",
    "    first_value_len = len(list(a.values())[0])\n",
    "    v=[]\n",
    "    for i in range(first_value_len):\n",
    "        l={}\n",
    "        #print(i)\n",
    "        for qk, qv in a.items():\n",
    "            #print(qk)\n",
    "            l[qk] = qv[i]\n",
    "        if not all(value == None for value in l.values()):\n",
    "            v.append(l)\n",
    "    return v\n",
    "\n",
    "#resultant_json = {\"proc\": {\"summary\": {\"title\": [{\"append_to_tag\": \"\", \"text\": \"\"}],\n",
    "#                                       \"auxiliary_headers_text_file\": []}}}\n",
    "\n",
    "resultant_json = {\"proc\":{\"summary\":[\n",
    "    {\"title\":{\"append_to_tag\":\"\",\"text\":\"\"},\n",
    "     \"auxiliary_headers_text_file\":\"\",\n",
    "     \"check_for_amplitudes\":\"\"}]}}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "for i, j in df.groupby(\"parent\"):\n",
    "    print(\"parent: {}\".format(i))\n",
    "    values={}\n",
    "    parent = i\n",
    "    # find how many summary elements are present\n",
    "    path_prefix = j['File node'].iloc[0]\n",
    "    xpath = \"//\" + \"/\".join(path_prefix.split(\">\"))\n",
    "    number_of_elements = len(docTree.xpath(xpath))\n",
    "    #print(number_of_elements)\n",
    "    v = []\n",
    "    for element_number in range(number_of_elements):\n",
    "        for k, l in j.iterrows():\n",
    "            tag = str(l[\"File tag\"])\n",
    "            xpath_constructor = ''\n",
    "            xpath_constructor = \"//\" + \"/\".join(path_prefix.split(\">\")) + \"/Param/Path[text()='{}']/..\".format(tag)\n",
    "            whole_tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)]\n",
    "            print(\"tag: {}\".format(whole_tag_value))\n",
    "            print(xpath_constructor)\n",
    "            current_path = docTree.xpath(xpath_constructor)[element_number]\n",
    "            if current_path.xpath(\"./Content\"):\n",
    "                print(\"value: {}\".format(current_path.xpath(\"./Content\")[0].text))\n",
    "                #values[tag_value].append((path.xpath(\"./Content\")[0].text))\n",
    "            else:\n",
    "                print(None)\n",
    "                #values[tag_value].append(None)\n",
    "            print(\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2ca6d52-b557-4c5f-abfa-017f2abebc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docTree.xpath(\"//proc/summary/Param/Path[text()='::title:text']/../Content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "350a2130-a7e9-461c-8665-7cd9fa3a0697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***file type***\n",
      "proc > summary\n",
      "***group: ::title***\n",
      "***group: None***\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "for i, j in df.groupby(\"File node\"):\n",
    "    print(\"***file type***\")\n",
    "    print(i)\n",
    "    for i1, j1 in j.groupby(\"parent\"):\n",
    "        print(\"***group: {}***\".format(i1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23575ceb-2096-4fc7-b712-a84f8f1ee559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent: proc > summary\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "None\n",
      "###\n",
      "::auxiliary headers text file\n",
      "29\n",
      "::auxiliary headers text file\n",
      "{'auxiliary_headers_text_file': None}\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "::title:text\n",
      "12\n",
      "bvc\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"true val\"\n",
      "###\n",
      "::title:append to log\n",
      "21\n",
      "bvc\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::check for amplitudes\n",
      "22\n",
      "::check for amplitudes\n",
      "{'auxiliary_headers_text_file': None, 'title': {'text': None, 'append_to_log': '\"true val\"'}, 'check_for_amplitudes': '\"true\"'}\n",
      "tag: ['auxiliary_headers_text_file']\n",
      "//proc / summary/Param/Path[text()='::auxiliary headers text file']/..\n",
      "value: \"value2 auxillary\"\n",
      "###\n",
      "::auxiliary headers text file\n",
      "29\n",
      "::auxiliary headers text file\n",
      "{'auxiliary_headers_text_file': '\"value2 auxillary\"'}\n",
      "tag: ['title', 'text']\n",
      "//proc / summary/Param/Path[text()='::title:text']/..\n",
      "None\n",
      "###\n",
      "::title:text\n",
      "12\n",
      "bvc\n",
      "tag: ['title', 'append_to_log']\n",
      "//proc / summary/Param/Path[text()='::title:append to log']/..\n",
      "value: \"value2\"\n",
      "###\n",
      "::title:append to log\n",
      "21\n",
      "bvc\n",
      "tag: ['check_for_amplitudes']\n",
      "//proc / summary/Param/Path[text()='::check for amplitudes']/..\n",
      "value: \"true\"\n",
      "###\n",
      "::check for amplitudes\n",
      "22\n",
      "::check for amplitudes\n",
      "{'auxiliary_headers_text_file': '\"value2 auxillary\"', 'title': {'text': None, 'append_to_log': '\"value2\"'}, 'check_for_amplitudes': '\"true\"'}\n",
      "########\n",
      "[{'auxiliary_headers_text_file': None, 'title': {'text': None, 'append_to_log': '\"true val\"'}, 'check_for_amplitudes': '\"true\"'}, {'auxiliary_headers_text_file': '\"value2 auxillary\"', 'title': {'text': None, 'append_to_log': '\"value2\"'}, 'check_for_amplitudes': '\"true\"'}]\n"
     ]
    }
   ],
   "source": [
    "# code 4\n",
    "import re\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "parser = etree.XMLParser(encoding='utf-8')\n",
    "# Reading the XML file\n",
    "docTree = etree.parse(\"pgs.jobxml\", parser)\n",
    "\n",
    "def flatten(a):\n",
    "    first_value_len = len(list(a.values())[0])\n",
    "    v=[]\n",
    "    for i in range(first_value_len):\n",
    "        l={}\n",
    "        #print(i)\n",
    "        for qk, qv in a.items():\n",
    "            #print(qk)\n",
    "            l[qk] = qv[i]\n",
    "        if not all(value == None for value in l.values()):\n",
    "            v.append(l)\n",
    "    return v\n",
    "\n",
    "#resultant_json = {\"proc\": {\"summary\": {\"title\": [{\"append_to_tag\": \"\", \"text\": \"\"}],\n",
    "#                                       \"auxiliary_headers_text_file\": []}}}\n",
    "\n",
    "resultant_json = {\"proc\":{\"summary\":[\n",
    "    {\"title\":{\"append_to_tag\":\"\",\"text\":\"\"},\n",
    "     \"auxiliary_headers_text_file\":\"\",\n",
    "     \"check_for_amplitudes\":\"\"}]}}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"xmldata.csv\")\n",
    "#df.groupby(\"File tag\").filter(lambda gr: ~gr.File.str.contains(\"cream\").any())\n",
    "#print(df)\n",
    "v = []\n",
    "for i, j in df.groupby(\"File node\"):\n",
    "    print(\"parent: {}\".format(i))\n",
    "    values={}\n",
    "    parent = i\n",
    "    # find how many summary elements are present\n",
    "    path_prefix = j['File node'].iloc[0]\n",
    "    xpath = \"//\" + \"/\".join(path_prefix.split(\">\"))\n",
    "    number_of_elements = len(docTree.xpath(xpath))\n",
    "    #print(number_of_elements)\n",
    "    \n",
    "    \n",
    "    for element_number in range(number_of_elements):\n",
    "        v1 = {}\n",
    "        for k, l in j.iterrows():\n",
    "            tag = str(l[\"File tag\"])\n",
    "            xpath_constructor = ''\n",
    "            xpath_constructor = \"//\" + \"/\".join(path_prefix.split(\">\")) + \"/Param/Path[text()='{}']/..\".format(tag)\n",
    "            whole_tag_value = [re.sub(\"\\s\", \"_\", items.strip(\"::\")) for items in re.split(\"(?<!:):(?!:)\", tag)]\n",
    "            print(\"tag: {}\".format(whole_tag_value))\n",
    "            print(xpath_constructor)\n",
    "            current_path = docTree.xpath(xpath_constructor)[element_number]\n",
    "            current_value=''\n",
    "            if current_path.xpath(\"./Content\"):\n",
    "                current_value = current_path.xpath(\"./Content\")[0].text\n",
    "                print(\"value: {}\".format(current_path.xpath(\"./Content\")[0].text))\n",
    "                #values[tag_value].append((path.xpath(\"./Content\")[0].text))\n",
    "            else:\n",
    "                current_value = None\n",
    "                print(None)\n",
    "                #values[tag_value].append(None)\n",
    "            print(\"###\")\n",
    "            print(tag)\n",
    "            print(len(tag))\n",
    "            if len(whole_tag_value) > 1:\n",
    "                print(\"bvc\")\n",
    "                #for i1 in tag[:-1]:\n",
    "                    #if i1 in v1:\n",
    "                v1.setdefault(whole_tag_value[0],{}).update({whole_tag_value[-1]: current_value})\n",
    "                        \n",
    "            else:\n",
    "                print(tag)\n",
    "                v1[whole_tag_value[-1]] = current_value\n",
    "                print(v1)\n",
    "        v.append(v1)\n",
    "        \n",
    "        \n",
    "print(\"########\")\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a86a7243-ab8f-40f5-aab2-01cd75791ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': {}}\n",
      "{}\n",
      "{'text': '2'}\n"
     ]
    }
   ],
   "source": [
    "c={}\n",
    "q=['title', 'text']\n",
    "for i in q[:-1]:\n",
    "    if not i in c:\n",
    "        c[i] = {}\n",
    "    print(c)\n",
    "    c = c[i]\n",
    "    print(c)\n",
    "#print(c)\n",
    "c[q[-1]] = '2'\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbea9765-d783-4cf4-9ba4-7323aa887258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': {'c': 'v'}}\n"
     ]
    }
   ],
   "source": [
    "c={}\n",
    "\n",
    "c.setdefault('title',{}).update({'c':'v'})\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef5394-7960-4fd2-9a9f-a4ade2985a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
